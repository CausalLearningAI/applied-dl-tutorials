{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C5Ct9yoZKYa"
   },
   "source": [
    "In this tutorial, we will cover:\n",
    "\n",
    "- Convolution operators on non-Euclidean domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzZFFAD7ujN4"
   },
   "source": [
    "##Import dependencies (run the following cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5CApnc6X4bFq",
    "outputId": "43f53c02-c5de-4860-cdf5-55b0b8d712b2"
   },
   "outputs": [],
   "source": [
    "# @title import/install dependencies\n",
    "\n",
    "!pip install networkx\n",
    "!pip install python-igraph\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2tGN_bJOcfd3"
   },
   "outputs": [],
   "source": [
    "# @title reproducibility stuff\n",
    "\n",
    "import random\n",
    "\n",
    "np.random.seed(4)\n",
    "random.seed(4)\n",
    "\n",
    "torch.cuda.manual_seed(4)\n",
    "torch.manual_seed(4)\n",
    "torch.backends.cudnn.deterministic = (\n",
    "    True  # Note that this Deterministic mode can have a performance impact\n",
    ")\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNWCNEb9ob_g"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciu1e5TBVksY"
   },
   "source": [
    "## Information embedded in data\n",
    "\n",
    "In machine learning we build models using the information contained in a collection of samples.\n",
    "\n",
    "We can look at the information embedded in data as a combination of:\n",
    "- The **signal**, encoding the features of the variables.\n",
    "- The **structure**, encoding the relations between variables.\n",
    "\n",
    "Formally we encode the features of these variables in a function $f$ over a domain $\\Omega$ which defines the relations.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/lucmos/DLAI-s2-2020-tutorials/master/09/pics/data-signal-domain.PNG)\n",
    "\n",
    "\n",
    "\n",
    "Sometimes most of the information is in the signal.\n",
    "> Consider the problem of predicting the hour of the day from pixels in the [Monet's paintings of the Rouen Cathedral](https://en.wikipedia.org/wiki/Rouen_Cathedral_(Monet_series)). Can you solve this problem without considering the structure?\n",
    ">\n",
    ">![alt text](https://raw.githubusercontent.com/lucmos/DLAI-s2-2020-tutorials/master/09/pics/picture.png)\n",
    ">\n",
    "> **EXERCISE**: Sketch a learning pipeline to solve this problem without considering the structure.\n",
    "\n",
    "Sometimes most of the information is in the structure.\n",
    "> Consider the problem of predicting members of a chess club in a social network. You know the true label of few people (member/not member), and some features for each person, say age and gender. Can you solve this problem without considering the structure?\n",
    "\n",
    ">Another relevant example are proteins, which are essential elements for growth and repair, good functioning and structure of all living cells. Proteins are macromolecules composed by a chain of  smaller molecules (the amminoacids) which spontanuosly folds in a complex 3D arrangement. The functionality of proteins comes almost entirely from their shapes rather than the specific atoms of their composition.\n",
    "\n",
    "To learn proper models, we should be able to grasp all the relevant information in our data, whether in the signal or in the structure.\n",
    "\n",
    "Notice that often the mutual information between the signal and the structure is non-zero, i.e. you may obtain some information about the signal observing only the structure and viceversa. Nevertheless it may be much easier to extract the information from one of the two.\n",
    "\n",
    "\n",
    "> Consider again the proteins, suppose to have a dataset composed of 3d triangle meshes encoding their shapes and some categorical features encoded as functions defined on each vertex of the mesh, such as the amminoacid in that region of the protein and its positional encoding (the position of the amminoacid in the chain).\n",
    ">\n",
    ">This kind of representation is redundant; the information about the shape of the protein is already contained in the chain of amminoacids, since this folds in a deterministic way. Your structure information is already encoded in the signal. In theory you can predict shape-dependent quantities, such as the degree of interaction between different proteins, using only the information in the signal; nevertheless extracting the shape information from the sequence of amminoacids is a very hard problem by itself (known as protein folding, one of the biggest open problems in biology $^1$) and in practice you obtain much better results using the shape information encoded in the triangle mesh. See for instance [*Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning (2019)*](https://www.nature.com/articles/s41592-019-0666-6).\n",
    "\n",
    "$1$. In 2020 we made a huge [step forward](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology) in the problem of protein folding thanks to deep learning. Can we say that protein folding has been solved by AlphaFold 2? [Not quite](http://backreaction.blogspot.com/2021/01/has-protein-folding-been-solved.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIvWSSFt5VDO"
   },
   "source": [
    "## Digesting *a priori* the information in the structure\n",
    "\n",
    "We have already learned how to consider the structure information in a simple case; when the domain $\\Omega$ is the Euclidean $\\mathbb{R}^2$, i.e. when the relations between variables are represented by a 2-dimensional grid, such as the pixels of an image.\n",
    "\n",
    "![immagine griglia 2d](https://raw.githubusercontent.com/lucmos/DLAI-s2-2020-tutorials/master/09/pics/euclidean.PNG)\n",
    "\n",
    "The filters of a convolutional neural network elaborate pixels considering only their neighbors and are applied with the same weights all over the image. In this way **CNNs are digesting *a priori* the structure information**, using the properties of the domain -- the translational invariance and the locality of neighbours -- to **reduce the free parameters of the model**. This leads to a crucial speed-up of the training process and allows larger and more powerful models.\n",
    "\n",
    "CNNs can be naturally extended to general Euclidean domains $\\mathbb{R}^n$, but what can we do when $\\Omega \\neq \\mathbb{R}^n$?\n",
    "\n",
    "In many different fields such as Biology, Physics, Social Sciences and Computer Graphics we have to process signals defined on non-Euclidean domains, such as Graphs $\\Omega = G(\\mathcal{V, E})$ or [Manifolds](https://en.wikipedia.org/wiki/Manifold) $\\Omega = \\mathcal{X}$.\n",
    "\n",
    "We would like to come out with a solution analoguous to CNNs; digesting *a priori* the structure information to reduce the free parameters proved to be very convenient in a learning setting based on a gradient descent optimization.\n",
    "\n",
    "### Representing non-Euclidean data in an Euclidean memory\n",
    "\n",
    "Working with non-Euclidean domains provides a further challenge in representing the data.\n",
    "\n",
    "In the Euclidean setting, encoding the data in ordered matrices, vectors or tensors is so natural and effective that we do not even think about alternatives, and indeed the computer memory structure is itself Euclidean.\n",
    "\n",
    "In the non-Euclidean setting we have many alternatives, consider for instance a manifold $\\mathcal{X}$. It can be represented by a triangle mesh with vertices, edges and faces $\\mathcal{V,E,F}$, by a n-polygonal mesh, where we admit also non-triangle faces, by a simple point cloud or by a subdivision surface.\n",
    "\n",
    "And even when we have chosen the representation, we still have to come out with a last encoding procedure to store our data in matrices and tensors as required by the Euclidean structure of the physical memory in our computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI06SGEA3sGa"
   },
   "source": [
    "## GCN & CORA\n",
    "\n",
    "The code in the following sections comes mainly from [this repository](https://github.com/tkipf/pygcn) and it is inspired by the paper [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907), where Thomas Kipf presents the Graph Convolutional Networks in PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSu-7fFTZ_mC"
   },
   "source": [
    "### The CORA dataset\n",
    "\n",
    "The CORA dataset is a much bigger dataset when compared to the Karate graph, the task is again node classification.\n",
    "\n",
    "In the CORA graph we have:\n",
    "- Each **node** is a Machine Learning paper.\n",
    "- An **edge** represents one citation from one paper to another.\n",
    "- Each node is classified into one of seven possible Machine Learning sub-fields:\n",
    " - Case Based\n",
    " - Genetic Algorithms\n",
    " - Neural Networks\n",
    " - Probabilistic Methods\n",
    " - Reinforcement Learning\n",
    " - Rule Learning\n",
    " - Theory\n",
    "\n",
    "We will use a subset of the CORA dataset, preprocessed as suggested by [Thomas Kipf](https://github.com/tkipf/pygcn/tree/master/data/cora):\n",
    "\n",
    "- It considers only papers that are cited or cite at least once.\n",
    "- The words are [stemmed](https://en.wikipedia.org/wiki/Stemming)\n",
    "- Stopwords and infrequent words are removed.\n",
    "\n",
    "This subset contains **2708** paper with **1433** unique words.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "[Here](http://networkrepository.com/cora.php) you can have fun exploring the complete CORA dataset, and many other graph datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzzfOLUbcm4s"
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Case_Based\",\n",
    "    \"Genetic_Algorithms\",\n",
    "    \"Neural_Networks\",\n",
    "    \"Probabilistic_Methods\",\n",
    "    \"Reinforcement_Learning\",\n",
    "    \"Rule_Learning\",\n",
    "    \"Theory\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQQDaBv9aFHd"
   },
   "source": [
    "### Dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FcOB7p4f5HD",
    "outputId": "39cded69-1daf-4393-ccf1-9b10e088b26e"
   },
   "outputs": [],
   "source": [
    "# The preprocessed CORA is contained in this repository under ./data/cora\n",
    "!git clone https://github.com/tkipf/pygcn.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2hQAChyf8Wh"
   },
   "source": [
    "The directory `pygnc/data/cora` contains two files: `cora.content` and `cora.cites`.\n",
    "\n",
    "The `cora.content` contains the description of each node. For each line it contains:\n",
    " - The id of the node.\n",
    " - The [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) text representation.\n",
    " - The label of that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "NMOP7gdegneC",
    "outputId": "9a3bcba4-6828-45b0-b6f6-37fe671e3bb3"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "headers = [\"PaperID\"] + [f\"word{i}\" for i in range(1433)] + [\"label\"]\n",
    "pandas.read_csv(\"pygcn/data/cora/cora.content\", sep=\"\\t\", names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_MIw5cNg0OE"
   },
   "source": [
    "The `cora.cites` contains the relationships between nodes. For each line it contains:\n",
    "\n",
    "- The first entry is id of the cited paper\n",
    "- The second entry id of the citing paper\n",
    "\n",
    "That is, the direction of the entry is right to left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HzuQL4u5h1c-",
    "outputId": "37573ddd-625d-40ca-fa4a-c1346c38420e"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "headers = [\"Cited PaperID\", \"Citing PaperID\"]\n",
    "pandas.read_csv(\"pygcn/data/cora/cora.cites\", sep=\"\\t\", names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdnMB_qeh8Ij"
   },
   "source": [
    "### Data loading\n",
    "\n",
    "The repository provides python functions to parse the preprocessed data.\n",
    "\n",
    "It returns the adjacency matrix, the node features, the labels for each node, the indices to split into train-test:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wtNIwjAiWoP",
    "outputId": "c14041ec-0683-4583-9e5c-95d9bf32f3bd"
   },
   "outputs": [],
   "source": [
    "# Add the folder to the python path\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"./pygcn/pygcn\")\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test = load_data(path=\"pygcn/data/cora/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c89xEUOfk5pd",
    "outputId": "123ec55d-8c24-4f8d-9084-7df9b731e17d"
   },
   "outputs": [],
   "source": [
    "# As expected its shape is (num_paper, num_paper)\n",
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjMglHKMxjPe",
    "outputId": "1c07720c-d834-43ff-b158-f59cdd2ca540"
   },
   "outputs": [],
   "source": [
    "# Each paper has 1433 features. The Bag Of Words representation of its text (i.e., the set of words in the text)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "DATDX8IzzsOH"
   },
   "outputs": [],
   "source": [
    "# @title utility functions\n",
    "\n",
    "\n",
    "def get_predictions(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    return correct\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    correct = get_predictions(output, labels)\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def plot_loss(losses):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=list(range(len(losses))),\n",
    "            y=losses,\n",
    "            # name=\"Name of Trace 1\"       # this sets its legend entry\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Train loss\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        font=dict(family=\"Courier New, monospace\", size=18, color=\"#7f7f7f\"),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "def refresh_bar(bar, desc):\n",
    "    bar.set_description(desc)\n",
    "    bar.refresh()\n",
    "\n",
    "\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import igraph\n",
    "\n",
    "\n",
    "def plot_graph(adj, node_colors, colors_legend=classes, title=\"CORA graph\", layt=None):\n",
    "    N = adj.shape[0]\n",
    "    adj = adj.coalesce()\n",
    "    edgeA, edgeB = adj.indices()[0, :], adj.indices()[1, :]\n",
    "    edgeA = edgeA.tolist()\n",
    "    edgeB = edgeB.tolist()\n",
    "\n",
    "    G = igraph.Graph.Adjacency((adj.to_dense() > 0).tolist())\n",
    "    if layt is None:\n",
    "        layt = G.layout(\"fr_3d\")\n",
    "\n",
    "    Xn = [layt[k][0] for k in range(N)]  # x-coordinates of nodes\n",
    "    Yn = [layt[k][1] for k in range(N)]  # y-coordinates\n",
    "    Zn = [layt[k][2] for k in range(N)]  # z-coordinates\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    Ze = []\n",
    "    for e in zip(edgeA, edgeB):\n",
    "        Xe += [layt[e[0]][0], layt[e[1]][0], None]  # x-coordinates of edge ends\n",
    "        Ye += [layt[e[0]][1], layt[e[1]][1], None]\n",
    "        Ze += [layt[e[0]][2], layt[e[1]][2], None]\n",
    "\n",
    "    trace1 = go.Scatter3d(\n",
    "        x=Xe,\n",
    "        y=Ye,\n",
    "        z=Ze,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"rgb(125,125,125)\", width=1),\n",
    "        hoverinfo=\"none\",\n",
    "    )\n",
    "\n",
    "    trace2 = go.Scatter3d(\n",
    "        x=Xn,\n",
    "        y=Yn,\n",
    "        z=Zn,\n",
    "        mode=\"markers\",\n",
    "        name=\"actors\",\n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            size=6,\n",
    "            color=node_colors,\n",
    "            colorscale=\"Viridis\",\n",
    "            line=dict(color=\"rgb(50,50,50)\", width=0.5),\n",
    "        ),\n",
    "        text=colors_legend,\n",
    "        hoverinfo=\"text\",\n",
    "    )\n",
    "\n",
    "    axis = dict(\n",
    "        showbackground=False,\n",
    "        showline=False,\n",
    "        zeroline=False,\n",
    "        showgrid=False,\n",
    "        showticklabels=False,\n",
    "        title=\"\",\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        width=800,\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        scene=dict(\n",
    "            xaxis=dict(axis),\n",
    "            yaxis=dict(axis),\n",
    "            zaxis=dict(axis),\n",
    "        ),\n",
    "        margin=dict(t=100),\n",
    "        hovermode=\"closest\",\n",
    "    )\n",
    "\n",
    "    data = [trace1, trace2]\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    return fig, layt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw1BQmuDigbv"
   },
   "source": [
    "### CORA Graph\n",
    "\n",
    "Let's visualize the graph!\n",
    "\n",
    "As you can see, the graph has many disconnected components, many of which are very small. The preprocessing ensures that each component has at least 2 nodes.\n",
    "\n",
    "\n",
    "Note that in the visualization, nodes with the same colors have the same label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "d9AZPjs2dfPa",
    "outputId": "c7aad083-12bd-41c1-f21a-26db5708375a"
   },
   "outputs": [],
   "source": [
    "fig, layt = plot_graph(adj, labels)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PFJfu0OxCjn"
   },
   "source": [
    "### MLP approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IhSUKyMx0Zn"
   },
   "source": [
    "The simplest approach is to use a Multi Layer Perceptron on the features of each node, independently.\n",
    "\n",
    "This means that we aim to predict the sub-field of each machine learning paper looking exclusively at its text, encoded in a BOW. We're not considering at all at the structure of the graph, i.e. the citations that link the papers.\n",
    "\n",
    "You can see this approach as using only the **signal** part of the data, ignoring the **structure**.\n",
    "\n",
    "We can draw a parallel with a task in the image domain: predicting if a pixel belongs to a part of the image where there is sky or not. This MLP approach would independently process each pixel in an image, without looking at its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbDgXWwz9nCK"
   },
   "outputs": [],
   "source": [
    "def mlp_accuracy(model):\n",
    "    \"\"\"\n",
    "    Perfom a forward pass `y_pred = model(x)` and computes the accuracy\n",
    "    between `y_pred` and `y_true`\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_pred = model(features[idx_test])\n",
    "    acc = accuracy(y_pred, labels[idx_test])\n",
    "    print(f\"Accuracy: {acc:.5}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAW_VNQJyaR5"
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1433, 500), nn.ReLU(), nn.Linear(500, 100), nn.ReLU(), nn.Linear(100, 7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey2II_aJyktg",
    "outputId": "2b340ffe-a4f3-425f-e125-d63b51b5e117"
   },
   "outputs": [],
   "source": [
    "print(\"[MLP] before training\")\n",
    "_ = mlp_accuracy(mlp)\n",
    "print(\n",
    "    f\"Which is comparable to/worse than random guessing (there are 7 classes in total): {1/7=:.5}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "070GPhMyg4U9"
   },
   "source": [
    "Cora graph visualization:\n",
    "- **Yellow nodes: correct predictions**\n",
    "- **Purple nodes: wrong predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "bDyyJht_gzYL",
    "outputId": "e1490f4e-6bc9-40a4-f374-ad7c308859d4"
   },
   "outputs": [],
   "source": [
    "correct = get_predictions(mlp(features), labels)\n",
    "fig, layt = plot_graph(adj, correct, title=\"MLP performance before training\", layt=layt)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "1c23wZQO0VFB",
    "outputId": "83726028-5662-4674-eb77-6d9e4132f676"
   },
   "outputs": [],
   "source": [
    "# Let's now train the MLP model\n",
    "opt = optim.Adam(mlp.parameters())\n",
    "\n",
    "losses = []\n",
    "mlp.train()\n",
    "\n",
    "for epoch in trange(500):\n",
    "    opt.zero_grad()\n",
    "    output = mlp(features[idx_train])\n",
    "    loss = F.cross_entropy(output, labels[idx_train])  # train only on the train samples\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIca212f1eIG",
    "outputId": "893497d2-6446-4897-ba64-b8216784b58a"
   },
   "outputs": [],
   "source": [
    "print(\"[MLP] after training\")\n",
    "accmlp = mlp_accuracy(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPS9njkRhCQj"
   },
   "source": [
    "Cora graph visualization:\n",
    "- Yellow nodes: correct predictions\n",
    "- Purple nodes: wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "wYNHpk9phg0t",
    "outputId": "db4fe7e8-4fc1-4663-8859-1226f1e38614"
   },
   "outputs": [],
   "source": [
    "correct = get_predictions(mlp(features), labels)\n",
    "fig, layt = plot_graph(adj, correct, title=\"MLP performance after training\", layt=layt)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8EJ5h852F9t"
   },
   "source": [
    "### Graph convolutional network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8UKA_EQ2ytB"
   },
   "source": [
    "We can define an equivalent of the `nn.Layer` that uses the adjacency matrix (and therefore the data structure) in the forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTZM34Gj2KYm"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "\n",
    "        # A nn.Parameter is a normal tensor\n",
    "        # that is automatically registered as a model parameter\n",
    "        # so that it is inclued in `model.parameters()`.\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.spmm(adj, support)  # sparse matrix multiplication\n",
    "        # note that we are using the WHOLE graph to compute the output since we are using the adjacency matrix\n",
    "        return output + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_etaL_23C68"
   },
   "source": [
    "These layers can be combined together to build complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUq5cMgm519n"
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_features: int, hidden_dim: int, num_classes: int):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_features, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = F.relu(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhIE-U4X889k"
   },
   "outputs": [],
   "source": [
    "def gcn_accuracy(model):\n",
    "    \"\"\"\n",
    "    Perfom a forward pass `y_pred = model(x)` and computes the accuracy\n",
    "    between `y_pred` and `y_true`.\n",
    "\n",
    "    It is particuarly tricky to perform batching in GCN.\n",
    "    As you can see, here the forward pass is performed on the whole graph\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_pred = model(features, adj)  # Do you notice the difference?\n",
    "    acc = accuracy(y_pred[idx_test], labels[idx_test])\n",
    "    print(f\"Accuracy: {acc:.5}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a1V1oAM_xGM",
    "outputId": "5a195fb2-478e-4c1d-c534-0702100cf6f0"
   },
   "outputs": [],
   "source": [
    "gcn = GCN(1433, 50, 7)\n",
    "\n",
    "print(\"[GCN] before training\")\n",
    "_ = gcn_accuracy(gcn)\n",
    "print(\n",
    "    f\"Which is comparable to/worse than random guessing (there are 7 classes in total): {1/7=:.5}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk7Gd5DnhEGG"
   },
   "source": [
    "Cora graph visualization:\n",
    "- Yellow nodes: correct predictions\n",
    "- Purple nodes: wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "-cH7M8dzhzhk",
    "outputId": "c09709da-a40c-4008-f2cb-63c6d3bdf720"
   },
   "outputs": [],
   "source": [
    "correct = get_predictions(gcn(features, adj), labels)\n",
    "fig, layt = plot_graph(adj, correct, title=\"GCN performance before training\", layt=layt)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "T4jBQ7aP8uXG",
    "outputId": "5ec68dcf-098e-49b9-9531-22e004390489"
   },
   "outputs": [],
   "source": [
    "# Let's now train the GCN model\n",
    "opt = optim.Adam(gcn.parameters())\n",
    "\n",
    "losses = []\n",
    "gcn.train()\n",
    "\n",
    "for epoch in trange(1000):\n",
    "    opt.zero_grad()\n",
    "    output = gcn(\n",
    "        features, adj\n",
    "    )  # compute all outputs, even for the nodes in the test set\n",
    "    loss = F.cross_entropy(\n",
    "        output[idx_train], labels[idx_train]\n",
    "    )  # Train only on the train samples!\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Owvq_Yc-Q8d",
    "outputId": "a99c927b-e8a7-4d8e-d7b7-7625d15c573e"
   },
   "outputs": [],
   "source": [
    "print(\"[GCN] after training\")\n",
    "accgcn = gcn_accuracy(gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67Rzq_vshF3a"
   },
   "source": [
    "Cora graph visualization:\n",
    "- Yellow nodes: correct predictions\n",
    "- Purple nodes: wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "cUdSCmciiFqn",
    "outputId": "ec5483da-b417-44f7-9f61-0af032d6cf13"
   },
   "outputs": [],
   "source": [
    "correct = get_predictions(gcn(features, adj), labels)\n",
    "fig, layt = plot_graph(adj, correct, title=\"GCN performance after training\", layt=layt)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQUi-P5H-3MG",
    "outputId": "e3f16738-49c0-4caa-cd90-6087db52ccbc"
   },
   "outputs": [],
   "source": [
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(\"Number of parameters MLP: \", num_params(mlp))\n",
    "print(\"Number of parameters GCN: \", num_params(gcn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtdcDnbS73HO"
   },
   "source": [
    "### Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "NPM53CWZ_LWL",
    "outputId": "349492c5-d59c-4020-ff48-b6029d693789"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure([go.Bar(x=[\"MLP\", \"GCN\"], y=[accmlp.item(), accgcn.item()])])\n",
    "fig.update_layout(\n",
    "    title=\"Performance comparison\", yaxis_title=\"Accuracy [%]\", xaxis_title=\"Model type\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9uKoD7eRULB"
   },
   "source": [
    "**Credits**\n",
    "\n",
    "- Geometric deep learning [tutorial](https://vistalab-technion.github.io/cs236781/tutorials/tutorial_09/)\n",
    "- Deep Learning and Applied AI course at Sapienza, [GNN lesson](https://github.com/erodola/DLAI-s2-2023)\n",
    "- Kipf T, Welling M. Semi-Supervised Classification with Graph Convolutional Networks (2016).\n",
    "- Bronstein M. M., et al. (2017) Geometric Deep Learning: Going beyond Euclidean data. IEEE Signal Process Mag 34(4)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
