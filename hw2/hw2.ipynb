{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtMVVWN-LOV2"
   },
   "source": [
    "# ISTA: Applied Deep Learning for Scientists -- Homework 2\n",
    "\n",
    "**Topics**: Language processing, Sequential models and Transformers\n",
    "\n",
    "This homework consists of two theoretical questions and one practical question.\n",
    "\n",
    "For the theoretical questions, you can type out the answers in cells dedicated for the answers (Markdown supports LaTeX equations).\n",
    "For the practical question, please fill in the missing blocks of code.\n",
    "Please submit the homeworks via email to all the TAs.\n",
    "\n",
    "Deadline: March 25, 2024, 11:55 PM.\n",
    "\n",
    "TAs: Dingling Yao (dingling.yao@ist.ac.at), Valentino Maiorca (valentino.maiorca@ist.ac.at), Sanketh Vedula (sanketh@campus.technion.ac.il)\n",
    "\n",
    "Name: < your name >\n",
    "\n",
    "ID: < your ID >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toWi9UxQL7ln"
   },
   "source": [
    "## Question 1 -- Bigram\n",
    "\n",
    "Consider the following toy example (similar to the one from Jurafsky & Martin (2015)):\n",
    "Training data:\n",
    "\n",
    "- < s > I am Sam < /s >\n",
    "- < s > Sam I am < /s >\n",
    "- < s > Sam I like < /s >  \n",
    "- < s > Sam I do like < /s >\n",
    "- < s > do I like Sam < /s >\n",
    "\n",
    "\n",
    "Assume that we use a bigram language model based on the above training data.\n",
    "\n",
    "1. Compute the Bigram probabilities as a table (as shown in the lecture).\n",
    "\n",
    "\n",
    "|  p( col / row) | < s > | I | am | Sam | like | do | < /s > |\n",
    "|--------|-------|---|----|-----|------|----|--------|\n",
    "| < s >  |       |   |    |     |      |    |        |\n",
    "| I      |       |   |    |     |      |    |        |\n",
    "| am     |       |   |    |     |      |    |        |\n",
    "| Sam    |       |   |    |     |      |    |        |\n",
    "| like   |       |   |    |     |      |    |        |\n",
    "| do     |       |   |    |     |      |    |        |\n",
    "| < /s > |       |   |    |     |      |    |        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqBxPj_XNu7c"
   },
   "source": [
    "2. Which of the following is the most probable sentence according to the model? Provide your arguments\n",
    "\n",
    "  (1) < s > Sam I do I like < /s >\n",
    "\n",
    "  (2) < s > Sam I am < /s >\n",
    "\n",
    "  (3) < s > I do like Sam I am < /s >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0yGxMPTN5LL"
   },
   "source": [
    "### **TODO**: Answer for question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bnQXerrORzh"
   },
   "source": [
    "# Question 2 -- Self-attention\n",
    "\n",
    "In a self-attention layer without trainable parameters (thus no QKV projection), an interesting behavior is observed. For an input sequence of length n, where each vector is uniformly drawn from a unit d-dimensional sphere and d is significantly larger than n (d â‰« n), the output sequence is nearly identical to the input. Why does this phenomenon occur? Please explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSxcu5DsOmpB"
   },
   "source": [
    "### **TODO**: Answer for question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AA5iAMIP7fW"
   },
   "source": [
    "# Question 3: Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYP_pGBVPLls",
    "outputId": "f1d6ceda-adfd-439c-e998-a2bdf9ad340e"
   },
   "outputs": [],
   "source": [
    "!pip install datasets lightning gensim transformers nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5MWpuGsPFMQ"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608,
     "referenced_widgets": [
      "e0dc07617c6245d2b0b3e949d12152ba",
      "e2189b628bde4f9da91d17acc0a1c025",
      "ab5cc9c1b6a44f7c8ebc5f7e4c1535d0",
      "e080c8a65a2d47219b3802d489261062",
      "82b5108994b74990a9621853830a25d8",
      "c35fc58154e44ba99c5e33a951b58f66",
      "417cf0b264f347d5a41dd5e392a053e9",
      "78c8f17363fb49079ba05b243f52ed19",
      "4f0b214e4c184c2db7a40de2f765793d",
      "e9da5bf180294ab8920e5a2468575629",
      "9085f90e8b4e468f9061fee8f52aeeab",
      "994c5c23f77d4ea8914e045a95c1e12c",
      "408383cd257048a08f94d6288ecafde5",
      "8b4fc06302334aab8bc809743bc7c226",
      "823e2a6706a74f51bcf5203cec58a77d",
      "a11cc199dd8a4dd0aa60ebdf6ca95bca",
      "d3566073b8eb4c5a88982ebd0e4d210f",
      "0e5d72df7d7044dcaf80373f0efd9288",
      "a1f1fff76b914692a63b6422cfc158d8",
      "140fd88c1d7f4875881d5f53de1e46e3",
      "1426c96cb51647b2ae43ead164a1d1a3",
      "726106f18d364bf2801eb4e07936d320",
      "d91dc15878b9426db2d08318a67cc7ae",
      "737e56384dde445a86189a5709dd3477",
      "04814596e1e645a593128801ba14fafb",
      "57ba80814f42427384f340d87a46a026",
      "545e27b1b7344df2baa662b3caca9937",
      "0d6e4a20189c44b1927f86182a20ab2f",
      "08f6149140124757ba91494b4aaea2fb",
      "d09b31a3149c466499c685be9c7d9a9c",
      "70a4941d79cc4023a591b3902ed89b69",
      "dd4e750814d645cfbead2162dfb8711e",
      "08c4635eb74b49c183bc151ce700c0b3",
      "51588fcc7bb746258155d7624f471527",
      "4861c4f4327245e49a7a7909546a59c3",
      "195e293e2de5489cb46736df05628acf",
      "ec4e510bae8343a99695335114215697",
      "5ca6275b17744a5ca51951c0fe50c866",
      "7407673ae5c44e328896cd55f81fdb32",
      "39e120649aa84d3d8fa93bbc548a19e2",
      "1438c5905de249cb9513e752685d2c74",
      "f1c423d1342b425b859cb891ab4733e1",
      "636eb01b7e154d748ca9f34f3353d13b",
      "3f3c6dd913db4d3fa517bc463ffc9338",
      "daf7e807ff394a199accd09342b4582f",
      "d4f08589db7245398f7b79a2511fc860",
      "66e5738e25984489951f45c2a76396bc",
      "790d00ebb3f445d18b25a0df4ed5f815",
      "4e12d82deeb34e0993443e80cb2ae20e",
      "f6bd3a40f9b2404282b57f4012251538",
      "9bdaa4b750584ab294b3afe894246c03",
      "f034e08d581b4a6ebccdfce054f9f266",
      "b37e322bb1364ae3a3f981b49dc679b8",
      "d69fb6caa6dd49a2b2a40c3e52160e2a",
      "cca7d7baa2fc46969a28691551261bd4",
      "359b8713afbd48ba991e9093fbe4dbbd",
      "da8b706fa39a4f1c8f60de8382f59965",
      "6428a69be9c04084b8150793aac62603",
      "de7378989732499c8f5ef63c6979b0c2",
      "225e759518cc42f79f146bd430006cc7",
      "b01c8e16e141486eb2cf56acb4c1774c",
      "fcd86dc88ded4ce3840062bde407ce45",
      "96671e78b7424d669a4726a34a1a25e5",
      "1a3eea486dac4cea8ea85a395e7e8894",
      "2a32204443b5482a84223514f101e314",
      "d9c04b7bf5c44b849d21f199d8ab4cfa",
      "dc20537f20f94cb29141cadb88a57d03",
      "e407431576e94971a5c63103b76fdcaf",
      "c46e54616f6144babab7012efddd13d0",
      "7ca8a0928df543f68a7edbab3e46021f",
      "d59355623a9e407986cf6847daa14e02",
      "cb9423b0fcf74a26b31277f2fe12aca6",
      "fbaf76065e184b719b11cd8856cf06bb",
      "2945e28ac6a44f92911360dadeabb570",
      "e56d477d631e4917bb9ad7785b55beba",
      "68950a8a0b7943ce8beff9eadcbec794",
      "cc53e90bf3b74a4b8c45b7f45a058f59"
     ]
    },
    "id": "EiWJTMkzPFMS",
    "outputId": "d4b2ebec-67c0-46bb-ab75-5b42b0ca8abd"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0AumdgOPFMS",
    "outputId": "eaab742b-2ceb-42d8-f184-81f462c788dc"
   },
   "outputs": [],
   "source": [
    "# Split the train dataset into train and validation preserving the same distribution of labels as the original one\n",
    "fit_data = dataset[\"train\"].train_test_split(\n",
    "    test_size=0.1, train_size=0.4, seed=42, stratify_by_column=\"label\"\n",
    ")\n",
    "train_data, val_data = fit_data[\"train\"], fit_data[\"test\"]\n",
    "test_data = dataset[\"test\"].train_test_split(\n",
    "    test_size=0.4, seed=42, stratify_by_column=\"label\"\n",
    ")[\"test\"]\n",
    "\n",
    "data = DatasetDict({\"train\": train_data, \"val\": val_data, \"test\": test_data})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12bHCNFmPFMS",
    "outputId": "e90fa503-3f4d-4817-8602-ce157e643733"
   },
   "outputs": [],
   "source": [
    "sample = data[\"train\"][0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuIpMZT6PFMT",
    "outputId": "74cf5a51-ba73-41d8-9659-3c915442667e"
   },
   "outputs": [],
   "source": [
    "data[\"train\"].features[\"label\"], data[\"train\"].features[\"label\"].int2str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bn9vthzVPFMT",
    "outputId": "be6a522a-43b0-4efa-f6ce-bd0c0c8725fb"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Mapping, Sequence, List, Any\n",
    "import typing as ty\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUWAXxsCPFMT"
   },
   "outputs": [],
   "source": [
    "def simple_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"A simple function to tokenize a given text.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356,
     "referenced_widgets": [
      "67ad094abd5841ae9c50dddb6ec9af60",
      "b52106a97cf0442d975498efc3d886b6",
      "b59c60b950964364ad5725e564bf8f8a",
      "51a955604a0943c2b176e52d391c524e",
      "5e0abe6a31c6439fa551c5cb8920e0bf",
      "5f07d06ca5ba4f1885c2452fba06089a",
      "f919bcd76e7749f78f4504a5c0c7d4b3",
      "74474d1b986e4cbe8fe9d345c81194e9",
      "8341cb81908d4e5dac5e4f06cc3f6594",
      "0479bcef1d2d4d73bc38dfe4119ace3f",
      "e284e3b2393f4ef8a126fab5dd206226",
      "9ee489dc47144f4f8ae6ad3062f19d35",
      "6adedd7b90e5410eaec95d1fd960e329",
      "90296b5bfa994d6aad4422dbd4644951",
      "38518ea4fab942a59287754d66244298",
      "81ae842909f34282bdf2fab06f4dc73d",
      "e88852ec85c14b96b2636276223e66e8",
      "b72dda21a198484c8c20dda181742a96",
      "797aa0da8f7e4ee095de1e8577eab642",
      "388f9c11f3e14e5d963940539b8b04c6",
      "f91520197903469da290c05f29f0fa91",
      "ac33483ead934b78ae9be62c4037c8d6",
      "a7a1f532f27c4339ac6107e436a159b4",
      "d2c17652c34a4f01b57c6755776cdebd",
      "afcef5ea7fee413aad3c73d67796d9e9",
      "1415f334e59d4867aa8d8afe005ba1c0",
      "d4af7450e5584c958473ceb4c0558de0",
      "4b253561bfcd4fe6bbedf2323606d0b8",
      "68ee6760c6d3427a97e11385fdae0d61",
      "828ac01b0411460e8d9b104b4184c2f9",
      "081a59074f054aaab21aa5123c18558c",
      "48d74a31fbc4486080a43b07bb41925c",
      "c1a6aa905780412d9d32cdb540bba969"
     ]
    },
    "id": "x1evbxl8PFMT",
    "outputId": "715a498f-0a7d-42c1-e562-681af78f1722"
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda x: {**x, \"tokenized\": simple_tokenize(x[\"text\"][:1000])})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFBzXRNePFMT",
    "outputId": "a77b4a90-8e01-4bdb-9c0b-73cc1004566c"
   },
   "outputs": [],
   "source": [
    "data[\"train\"][0]  # Now we have a new column called \"tokenized\" with the tokenized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRpIEWCgPFMT"
   },
   "outputs": [],
   "source": [
    "def token_count(tokenized_texts: Sequence[Sequence[str]]) -> Counter[str]:\n",
    "    \"\"\"Count the number of times each token appears in the tokenized texts.\"\"\"\n",
    "    tokens = [token for text in tokenized_texts for token in text]\n",
    "    token2count = Counter(tokens)\n",
    "    return token2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "hRHfY07Knnmh",
    "outputId": "4abd62f4-f240-48d2-f598-2cf230da4a10"
   },
   "outputs": [],
   "source": [
    "token2count: ty.Counter = token_count(data[\"train\"][\"tokenized\"])\n",
    "f\"Total number of unique tokens: {len(token2count)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAnbmwTJPFMT",
    "outputId": "eb26b470-312e-42ae-d6e1-9217205432c1"
   },
   "outputs": [],
   "source": [
    "token2count.most_common(10)\n",
    "# they are not very informative, are they? That's because we have not removed the stop words https://en.wikipedia.org/wiki/Stop_word (yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uY63sQENRCV1"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "en_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhV02JsVPFMT"
   },
   "outputs": [],
   "source": [
    "# some special tokens we will use\n",
    "PAD_TOKEN_STR = \"<pad>\"  # this is used to pad the sequences to the same length\n",
    "UNK_TOKEN_STR = (\n",
    "    \"<unk>\"  # this is used to represent tokens that are not in the vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Twk1YlRCV1"
   },
   "outputs": [],
   "source": [
    "token2count = Counter(\n",
    "    {token: count for token, count in token2count.items() if token not in en_stopwords}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFsb5GosPFMT",
    "outputId": "8bdb8aeb-598a-49e8-d84c-7a4fb2f945cc"
   },
   "outputs": [],
   "source": [
    "# we will restrict the vocabulary to the 10k most common tokens (which is ~10% of the total number of unique tokens)\n",
    "vocab_size = 7_000\n",
    "vocab = {\n",
    "    word: index\n",
    "    for index, word in enumerate(\n",
    "        [PAD_TOKEN_STR, UNK_TOKEN_STR]\n",
    "        + [token for token, _ in token2count.most_common(vocab_size)]\n",
    "    )\n",
    "}\n",
    "list(vocab.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v6VZJYQPFMU",
    "outputId": "fb2f6f6e-509c-4260-8958-558ff94a88ff"
   },
   "outputs": [],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyDti23LY3ZJ"
   },
   "source": [
    "## Encode the tokens using end2end trained embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlKNKJddQdKz"
   },
   "outputs": [],
   "source": [
    "encoding_dim: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOVAdCfWPFMU"
   },
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token2index: Mapping[str, int],\n",
    "        encoding_dim: int,\n",
    "        oov_token: str = UNK_TOKEN_STR,\n",
    "        pad_token: str = PAD_TOKEN_STR,\n",
    "        aggregation: str = \"mean\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert pad_token in token2index\n",
    "        assert oov_token in token2index\n",
    "\n",
    "        self.token2index = token2index\n",
    "        self.oov_index = self.token2index[oov_token]\n",
    "\n",
    "        # initialize the token weights randomly\n",
    "        token_embeddings = torch.randn(len(token2index), encoding_dim)\n",
    "        token_embeddings[token2index[oov_token]] = token_embeddings.mean(dim=0)\n",
    "        token_embeddings[token2index[pad_token]] = 0\n",
    "        self.aggregation = aggregation\n",
    "\n",
    "        self.token_embeddings = nn.Parameter(token_embeddings)\n",
    "\n",
    "    @classmethod\n",
    "    def collate_fn(cls, batch):\n",
    "        texts = [sample[\"text\"] for sample in batch]\n",
    "\n",
    "        token_ids = [\n",
    "            torch.as_tensor(\n",
    "                [\n",
    "                    vocab.get(token, vocab[UNK_TOKEN_STR])\n",
    "                    for token in sample[\"tokenized\"]\n",
    "                ]\n",
    "            )\n",
    "            for sample in batch\n",
    "        ]\n",
    "\n",
    "        max_len = max(len(sample) for sample in token_ids)\n",
    "        token_ids = torch.stack(\n",
    "            [F.pad(sample, (0, max_len - len(sample))) for sample in token_ids]\n",
    "        )\n",
    "\n",
    "        labels = [sample[\"label\"] for sample in batch]\n",
    "\n",
    "        return {\n",
    "            \"texts\": texts,\n",
    "            \"token_ids\": token_ids,\n",
    "            \"labels\": torch.as_tensor(labels),\n",
    "        }\n",
    "\n",
    "    def forward(self, batch: Mapping[str, Any]) -> torch.Tensor:\n",
    "        token_ids = batch[\"token_ids\"]  # (batch_size, max_len)\n",
    "        text_encodings = self.token_embeddings[\n",
    "            token_ids\n",
    "        ]  # (batch_size, max_len, space_dim)\n",
    "        # now we could aggregate the encodings for each text, to get a single encoding for each one...\n",
    "        if self.aggregation == \"mean\":\n",
    "            # ...a way to do this is to sum the encodings and divide by the number of (non-padding) tokens\n",
    "            mask = token_ids != self.token2index[PAD_TOKEN_STR]\n",
    "            text_lengths = mask.sum(dim=1).unsqueeze(1).float()\n",
    "            text_encodings = text_encodings.sum(dim=1) / text_lengths\n",
    "        elif self.aggregation == None:\n",
    "            # ...or we could just return the encodings for each token\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Invalid aggregation: {self.aggregation}. Are you implementing a new one? :]\"\n",
    "            )\n",
    "        return text_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFLA43sMPFMU"
   },
   "outputs": [],
   "source": [
    "encoder = TextEncoder(token2index=vocab, encoding_dim=encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzKZwUwPPFMU"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import lightning as pl\n",
    "from torchmetrics import MetricCollection, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhlF5T4NPFMU"
   },
   "outputs": [],
   "source": [
    "class SimpleClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder: nn.Module,\n",
    "        encoding_dim: int,\n",
    "        n_classes: int,\n",
    "        train_encoder: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if not train_encoder:\n",
    "            for param in encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.train_encoder = train_encoder\n",
    "        self.encoder = encoder\n",
    "        # we will use a linear probe to classify the encoded texts\n",
    "        self.classifier = nn.Linear(encoding_dim, n_classes)\n",
    "\n",
    "        # some metrics\n",
    "        self.train_metrics = MetricCollection(\n",
    "            {\"accuracy\": Accuracy(task=\"multiclass\", num_classes=n_classes)}\n",
    "        )\n",
    "        self.val_metrics = self.train_metrics.clone()\n",
    "        self.test_metrics = self.train_metrics.clone()\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        if not self.train_encoder:\n",
    "            self.encoder.eval()\n",
    "\n",
    "    def forward(self, texts: Sequence[Sequence[str]]) -> torch.Tensor:\n",
    "        # get a single encoding for each text\n",
    "        encoded = self.encoder(texts)\n",
    "        # and then classify it with the linear probe\n",
    "        return self.classifier(encoded)\n",
    "\n",
    "    def _step(self, batch, batch_idx, stage: str):\n",
    "        logits = self(batch)\n",
    "        loss = F.cross_entropy(logits, batch[\"labels\"].to(self.device))\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log_dict(\n",
    "            getattr(self, f\"{stage}_metrics\")(logits, batch[\"labels\"]),\n",
    "            on_step=stage == \"train\",\n",
    "            on_epoch=True,\n",
    "            prog_bar=stage == \"train\",\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, stage=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, stage=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, stage=\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Adam-driven deep learning\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0VIjx_DPFMU"
   },
   "outputs": [],
   "source": [
    "model = SimpleClassifier(\n",
    "    encoder,\n",
    "    encoding_dim=encoding_dim,\n",
    "    n_classes=train_data.features[\"label\"].num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htHTR2j38_PK",
    "outputId": "d9cc48c8-e109-482d-e2b3-b061cc5cb7db"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentence = \"This movie is great, the best I've seen!\"\n",
    "tokenizer_out = simple_tokenize(sentence)\n",
    "with torch.no_grad():\n",
    "    token_ids = torch.as_tensor(\n",
    "        [vocab.get(token, vocab[UNK_TOKEN_STR]) for token in tokenizer_out]\n",
    "    )\n",
    "    logits = model.classifier(model.encoder({\"token_ids\": token_ids[None]}))\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    print(\n",
    "        f\"The class is {train_data.features['label'].int2str(probs.argmax().item())} with a probability of {probs.max().item():.2%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsuEuEIrPFMV"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    collate_fn,\n",
    "    max_epochs: int,\n",
    "    batch_size: int,\n",
    "    num_workers: int = 1,\n",
    "    accelerator: str = \"gpu\",\n",
    "):\n",
    "    train_loader = DataLoader(\n",
    "        data[\"train\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        data[\"val\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        data[\"test\"],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, accelerator=accelerator)\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906,
     "referenced_widgets": [
      "e367f9b744f241c3b2f41cb9c1464b57",
      "3e01801db761449696dfae10e206729a",
      "702c5f2c55804286a40a56ae149f5ac7",
      "ec272079ee0a4981b3dfa186e7a835f9",
      "8d69590eb2844c7aa69902879af48086",
      "9f72285632a34909aec3d9c9efaf7c9d",
      "c40103238e7f43b7803d9b51c8a00585",
      "4610405c95414f7e8175c7bbe9057e31",
      "d94fbb3de06c456eb58da1ea0133cfe4",
      "9ab9ef02289849889c0eafa9e0eb23fa",
      "2c7dec337cfd4d559e60336e2a832d7d",
      "a4ee14b0be7d48eeaa20a72d3a8b232a",
      "c00dc2661e484fc49e3294ce5d62861f",
      "0976e492fc4c4b4f870e987a6afbeab2",
      "0a21652e872842f2b3f76c69232be4d6",
      "a1ecc3ee9a7845c58031d897810e90e9",
      "59f50bf319af4fb696541134551fcd0b",
      "5bbf8bd51ffd4295a5675967aaf2bdbc",
      "13ca14f3a13c46a18d405cc8076aaa79",
      "e9c9f53e674b4dba93e06638cb14b421",
      "87883f78944d4a11817b225b71bcefb0",
      "b849eec2f11c430893b82449afa56f3e",
      "528cdda7bbd84b1cb7870d1933591b8a",
      "f31de3feec1348a7ab813e91765ae1b0",
      "771ae1903aa74e188cb73ab51b3816e0",
      "7dd97bc42e824d1facfb4d9e7d66e1e3",
      "4c8960bdd01d40de9d2a89d358258741",
      "0865e7263b70471b84020d1665312468",
      "884765493b0f46849d828bad1104ed98",
      "f9f9b12c39384537a8493087c2215ed5",
      "f01f92bf18ae4f929cd52f74f978ee8e",
      "0ff9a5cdfbac4fcda14c551eda3095c1",
      "efadff08fb774a2fb9bff40dd5b30d7e",
      "7ffd2987146048dda0436e6fe36f20ba",
      "1c03dbb372b14bd7b70bed03dd78900d",
      "4cfa75f220874e59bb491e9423d7014b",
      "8bc05fe9f67f47c7afc7fcd5fc308c89",
      "70906313742b4657b5c0da5efdc926a5",
      "72c34bcac8af45fc969403adddc516e0",
      "82765fcb23224bdf9d65d16a12cd939c",
      "d3acc408db544c65a7fa73332a1b30d8",
      "4ebba1b7118544fd86f91d89f4da9b0a",
      "52b1e679b71f4688830099f697454776",
      "df54e0554af14855a317d23b13368ebb",
      "b103bb04ce0e4e63964ea504493f37c2",
      "10a3502ad6a54c6ea7e0ed4b67e97ff9",
      "48abc4c5833744c58178e5ffcc134d7c",
      "c9f2dc0c17c94434af1ba87d3fb64c1d",
      "cf968a9e45e245798f704cac442a31e6",
      "f945021c3b0b4c109855a986a83f84fb",
      "f1e4c01760424572b54fbc3f627deee3",
      "fa998f1517f94b029878b797b8f0f3a1",
      "3d62ef9f74b643288f7471f9461571c5",
      "f1bcacd8f65e41c8b358d0cca76a1564",
      "1aa26c10d3604abfb6e9d871bc503c16",
      "f23dc5dc2ec54f72bc79f51173b4735b",
      "fb3ff804aff54d408f4009c4ce77527e",
      "108f6461afd6449e81af3816845ee3cd",
      "ce936baf679048d7aba36605996ebcc3",
      "788b0425bf70423487d1eead960e5e14",
      "26357d2f27354979b9d5d52e486d762d",
      "6ca4fc1d2f9c4bc49d8242ea98bcac03",
      "9b22ed9497a94091a49b2e25a7fed100",
      "cbf5752af0694c509b19e4f210dd5da2",
      "3265d3b0840542e68a4a4ee1c28e0ec7",
      "bcda3479f7354e94b0725f9581d6b0cd"
     ]
    },
    "id": "eSprsVT2ditc",
    "outputId": "19f957b5-8f79-45e2-8f42-b39ee7593591"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    collate_fn=encoder.collate_fn,\n",
    "    max_epochs=3,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    accelerator=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuhdZAKjZVad"
   },
   "source": [
    "### Some qualitative evaluation of the obtained encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIOSk4usr_Nd",
    "outputId": "30dcc8c8-8aa6-4cae-8850-1de4201c9406"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentence = \"This movie is great, the best I've seen!\"\n",
    "tokenizer_out = simple_tokenize(sentence)\n",
    "with torch.no_grad():\n",
    "    token_ids = torch.as_tensor(\n",
    "        [vocab.get(token, vocab[UNK_TOKEN_STR]) for token in tokenizer_out]\n",
    "    )\n",
    "    logits = model.classifier(model.encoder({\"token_ids\": token_ids[None]}))\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    print(\n",
    "        f\"The class is {train_data.features['label'].int2str(probs.argmax().item())} with a probability of {probs.max().item():.2%}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFCmZ4-kUdv5",
    "outputId": "6e5a301b-8957-45a6-89d9-b7158217f8dc"
   },
   "outputs": [],
   "source": [
    "# the text encoder is so simple we can directly apply the classifier on top of the word encodings\n",
    "token_scores = model.classifier.cpu()(model.encoder.token_embeddings.detach().cpu())\n",
    "token_scores = token_scores.softmax(dim=-1)\n",
    "token_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Z5svx4uU-k8"
   },
   "outputs": [],
   "source": [
    "index2token = {index: token for token, index in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHhGcWMnVzgV",
    "outputId": "ab8bfee2-8c47-4016-c2c8-76f27bbab50f"
   },
   "outputs": [],
   "source": [
    "# most_negative_tokens\n",
    "most_negative_ids = (\n",
    "    token_scores[:, 0].topk(20).indices.tolist()\n",
    ")  # the first dimension corresponds to the positive class\n",
    "most_negative_tokens = [index2token[index] for index in most_negative_ids]\n",
    "most_negative_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRQ0oUCKWbyc",
    "outputId": "8909f9be-41ee-44d9-8e4c-595bb0e4e2c7"
   },
   "outputs": [],
   "source": [
    "# most_positive_tokens\n",
    "most_positive_ids = (\n",
    "    token_scores[:, 1].topk(20).indices.tolist()\n",
    ")  # the second dimension corresponds to the negative class\n",
    "most_positive_tokens = [index2token[index] for index in most_positive_ids]\n",
    "most_positive_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkavBkQAZc_X"
   },
   "source": [
    "## Encode the tokens using end2end trained embeddings, but with an RNN as pooling operation instead of a simple mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smEoBliLWfXk"
   },
   "outputs": [],
   "source": [
    "class RNNEncoder(TextEncoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token2index: Mapping[str, int],\n",
    "        encoding_dim: int,\n",
    "        hidden_dim: int,\n",
    "        oov_token: str = UNK_TOKEN_STR,\n",
    "        pad_token: str = PAD_TOKEN_STR,\n",
    "        rnn_type: str = \"lstm\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            token2index, encoding_dim, oov_token, pad_token, aggregation=\"rnn\"\n",
    "        )\n",
    "        rnn_type = rnn_type.lower()\n",
    "        assert rnn_type in {\"lstm\", \"gru\"}\n",
    "        self.rnn_type = rnn_type\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = getattr(nn, rnn_type.upper())(\n",
    "            encoding_dim, hidden_dim, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: Mapping[str, Any]) -> torch.Tensor:\n",
    "        token_ids = batch[\"token_ids\"]  # (batch_size, max_len)\n",
    "        mask = token_ids != self.token2index[PAD_TOKEN_STR]\n",
    "        text_lengths = mask.sum(dim=1)\n",
    "\n",
    "        token_encodings = self.token_embeddings[token_ids]\n",
    "        packed_encodings = nn.utils.rnn.pack_padded_sequence(\n",
    "            token_encodings, text_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_encodings)\n",
    "        return hidden[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vL-okC_Vditc",
    "outputId": "f9315f96-7209-4f42-cd70-edf62590d126"
   },
   "outputs": [],
   "source": [
    "model = SimpleClassifier(\n",
    "    RNNEncoder(token2index=vocab, encoding_dim=encoding_dim, hidden_dim=100),\n",
    "    encoding_dim=100,\n",
    "    n_classes=train_data.features[\"label\"].num_classes,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871,
     "referenced_widgets": [
      "8b7888887a0843ddb93a0cd29aadf524",
      "b5ba1240df7f49bea36579b880fb40b6",
      "76c8e0053ed14a2cb6e62679d9736079",
      "1de08bbe9ce14ec29f052a2fed787537",
      "26524b58168645ae95a7d3b23d6d123b",
      "a03117df92624eabac4de66fc36f82a9",
      "a02302ef6524487ba774ddb0762a87ab",
      "e3a47271554a4af389a2124cd4862196",
      "37f9f1d6529347d0964933d5bbe6d6e3",
      "a914371440bd40c7bba34c2acd2f8bd6",
      "da210bb6e1044eff9cc0336197fbf11c",
      "ed74f0b762724a56bdfad9576d1eb2a5",
      "de18e2f9ff414216a35774f78bae58b5",
      "e2104af0f5c74b71a8933d054b1e2970",
      "75345f473b414a57ae83fcbb368df021",
      "5a54ca29eb1246fdb396e4ab97f387e7",
      "82c8709170f44da2843cbfe715f6d13c",
      "c0fb33bc41a44111a2e611c497d2a167",
      "ad246739346a4d80bd749acfdfd7cc99",
      "0482d2b206cb45b3846c80e2482c2216",
      "6ee18b6e47524f628c257a79f3ef6001",
      "bc608e00afc9442a9009852312795431",
      "ed87e3bce2fe4d3999382cdef7e696b2",
      "9e231a11510d4063b96d53036fae8d9e",
      "32867bbbddc84fc4bb3070ec27c3a6e9",
      "acd56794fdda44c1acc88bb06dca2bf3",
      "acfb4be7e35b455cb190f8a3c59ffce9",
      "c8c4fb28f6634e4297bd7359c8339614",
      "7ca4da117fae48279088c8eaffc1495f",
      "727ee8fbd39949c49996788a6c3cfb74",
      "810e43e82e7243cb9171a01f2c8a9bdd",
      "4f8acfd600294fe2bde4896157fc9a9b",
      "0d37f504f5184f98a178f972ea191881",
      "e30f339fe2234796a70b4fe0d095e600",
      "1e98e264f8824ef6b6f96bdbc90617cc",
      "4da8b7ccbc3640b8884b6a123619ff35",
      "ac81f7dde02f48a08ad5f31ec1d3207c",
      "98b42828cf3c47698f0e5720c4882aa7",
      "6bc9b6e72af54e98ab5a4947c2d354bd",
      "34a8785eb7f04386a686e65eb43fb146",
      "a61b234d660f467ab348a1db9b5970a0",
      "aba7954b2c814b48b51ec18f4bb3e7f6",
      "7041484e484f4d998daf9ba6ac4532df",
      "5c2cbb862135429f9c8337f3daf58e5c",
      "1d9f3ac389194856831cf452e73c82e7",
      "94cee09414b64f278dab2c076c4afdda",
      "dce613848ad542d4a12feddbd05736ff",
      "52059ea6a780443e8cfb72d38ae68145",
      "5567c1d9487e4b0bb5e05798c4fe0a34",
      "7252f53047a24cc087243aa9ce197454",
      "53cff8bea7be407fb08e581df267b293",
      "01b076481cc0461fbbeedf6199978910",
      "1f0cfe2e524d4f47892b9a46a2cc3392",
      "9b26d07435364a2a9da2a1c05aa42492",
      "77760d107a5b4e189ff9269452c9070e",
      "879173d639b24be4a62932371659230a",
      "32524c6e23ca401db7756eb0af5624ce",
      "86927994e51c473099c0f5ac78169ce6",
      "6d7550f0fa654871b99575334c00430c",
      "9ef8f6649a0049aeb76a78e4fd08ae0d",
      "1d070afa998f4596b7f251368ac698af",
      "d341da1d8dd248df8b656c3f9406a9d9",
      "7719acf7c2b5430ab39ee9ba35893eef",
      "e0c00221db2744b993bfe41079036485",
      "9da8ca19feeb451fa475065cc8ed17a8",
      "8c33a9d40efc4661ba0faa82f724460b"
     ]
    },
    "id": "vSamo8IEditd",
    "outputId": "bd3c30ef-80bf-4e49-e2b7-fcecf685f270"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    collate_fn=encoder.collate_fn,\n",
    "    max_epochs=3,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    accelerator=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNGVAkxsZk9k"
   },
   "source": [
    "## Encode the tokens using pre-trained vectors from GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTq-arkc5G5y",
    "outputId": "3ee5daec-37e5-4c67-a66d-6861472b24fe"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# loading the pretrained word embeddings using gensim\n",
    "gensim_model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8erQRa-WRCWG",
    "outputId": "f659fb22-e763-47e2-8281-d6bc093a7682"
   },
   "outputs": [],
   "source": [
    "# an example of how to retrieve the embedding of a single word\n",
    "gensim_model[\"movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIg7eO0JzRLq"
   },
   "outputs": [],
   "source": [
    "class GensimEncoder(TextEncoder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        token2index: Mapping[str, int],\n",
    "        gensim_model,\n",
    "        oov_token: str = UNK_TOKEN_STR,\n",
    "        pad_token: str = PAD_TOKEN_STR,\n",
    "        aggregation: str = \"mean\",\n",
    "    ):\n",
    "        super().__init__(\n",
    "            token2index, 100, oov_token, pad_token, aggregation=aggregation\n",
    "        )\n",
    "\n",
    "        # OOV vector\n",
    "        oov_vector = torch.as_tensor(gensim_model[\"unk\"])\n",
    "\n",
    "        token_embeddings = []\n",
    "        token_embeddings.append(torch.zeros_like(oov_vector))\n",
    "        token_embeddings.append(oov_vector)\n",
    "        # we are skipping the first two since they are the special PAD and UNK tokens\n",
    "        for token, index in list(token2index.items())[2:]:\n",
    "            # we want to map each token to its token embedding according to the gensim_model\n",
    "            # we append each embedding (remember to convert to torch.Tensor) to the token_embeddings list\n",
    "            if token in gensim_model:\n",
    "                ...  # your code here\n",
    "            else:\n",
    "                # the token is not found in the gensim_model, we treat it as an OOV token\n",
    "                token_embeddings.append(oov_vector)\n",
    "                self.token2index[token] = self.oov_index\n",
    "\n",
    "        # then we convert the token_embeddings list of tensors to a single tensor\n",
    "        token_embeddings = torch.stack(token_embeddings, dim=0)\n",
    "\n",
    "        # requires_grad set to False means we are not training those parameters\n",
    "        self.token_embeddings = nn.Parameter(token_embeddings, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2zZUK9kRCWG",
    "outputId": "ffa5c5fb-bc21-4ef1-e5d7-8d79e37e6a14"
   },
   "outputs": [],
   "source": [
    "encoder = GensimEncoder(token2index=vocab, gensim_model=gensim_model)\n",
    "model = SimpleClassifier(\n",
    "    encoder,\n",
    "    encoding_dim=100,\n",
    "    n_classes=train_data.features[\"label\"].num_classes,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871,
     "referenced_widgets": [
      "7fa5762cd585400b9260961f1fe6e1d7",
      "9cfbdfa4c04f49ca89e5eacc39cc67b1",
      "11f3570f889d4aba99ffa63407421981",
      "05736b6f9f444cd5901695fc41697fdb",
      "a765bbb22cff49f6a46d060155605d80",
      "3d1bdb3decaf405c98a64ce9c8fdfc89",
      "bde554584d2948c5a167477687a9e3cc",
      "0f75c7e0ce6149ad8f3624443469649e",
      "aa082ce04bda40648ad4e8830f189661",
      "316a9088a6ad4d30906b0642b35bdbd2",
      "689ff6d423174533ba1b483940d493a6",
      "4fc508fe936d44a3aef07c436def565f",
      "7cbf2483b89347048539cfec6079c6b0",
      "2d62171089e14cac86284e0ac6177281",
      "368a9ac8284a4567b1b75d38e3809444",
      "ffbe516dbc644af6a0ae0e3a5c5ca07e",
      "200b8ce2d84f4f9591c833d254a619a5",
      "76656b20c7e54ecb80e3f9e23076b5b7",
      "6c11deeed6a947299d61149fbbfc3df2",
      "75faf5a30b3844faa68ae81a9c5e315b",
      "76d15f4982e548eb978072004c3ef8e3",
      "bca176733e9a477b9cf44893dfc84e2c",
      "df907de2e40f48f78ba1bfb8731d48ea",
      "7274097ada4b4e408fadd8be0a36c140",
      "755bd6cbdd7041b1b9d45a40b9c7a73d",
      "adc82f4b8ddc4fb8bfed77d1ad295499",
      "51405aa0d713470ea61f79c1b0748f46",
      "8e737955002e4ab5b14a4d1798d0fa0e",
      "97a79c4ae29640789026e8320466c172",
      "f29873ef3b424e108137a2900169ade2",
      "febc4ebd2e4741beae1d7206910e56a9",
      "d7eecaeddd5642ddb28cdfa155ac1e44",
      "008662e208e346688a59200d4c2cae1b",
      "af48a7f62d344ed987e8c1c82948fc19",
      "82f764a589c1470aa09f736040ee86cb",
      "87701ad939e74f36832566659da07539",
      "ac8f2ba967fd42acb7b9775ce8f9841f",
      "cdd7839974b0483aa7e2f489b34371fa",
      "08442a2ab5a3459798245d7f9fe2dae4",
      "2453015936eb43ddb7c08cc0653f0a2b",
      "3bc5795848af4bc9b0261c0fd6ae6c5d",
      "00e5d82943fa4ef6b0cb86d7fa3a0ae4",
      "b74f6e97d76f4d059a23ebe91d463a30",
      "8af5980572f2480eb38c60bf8bbb3762",
      "510f95ff334e4d15b8ab69c522ae75e8",
      "a20a9da222b94f868029bb95b71198f8",
      "25eeff2231e2463cbaee1bae090ec566",
      "b33b7097ce1a4424abb238725f2da545",
      "2b7959ed1f804011b5dcf334fd38cff6",
      "32e63a4d03a84d909755076cc9426117",
      "8e9bb0d5ad394d26986e7ba12d165a7c",
      "d9e67ff98c8c4fbd8bf20818ecb14153",
      "62423472577b443bb9a45aacda2b6219",
      "df63b6ab7ccc471681d68a4f60e92cd5",
      "cc028369d8be46d8b1b02d451a57b114",
      "7ea458b879a04ad584ffcf4b7ee462e7",
      "29f8faea189a47a6ab3f9f1050065113",
      "453c9690356f439a9f3a1d518101c778",
      "4a39aced3e2644798534a023b621307e",
      "5dab3ed55d27483495097ff1138bc3eb",
      "463d2e66b1da44d8aacfc76c48050a31",
      "69790e2b2066415ea8f7a3e04e544ba1",
      "669b86110ffe4019a0ae14faad35579e",
      "7a66cdcc2dc24e6da2c8cf3a3fa2f109",
      "8416b0614c5540c5b2377a1698b52f79",
      "dd29d7a0b0e24d02a644759b72a331ea"
     ]
    },
    "id": "1YrC_l1wRCWG",
    "outputId": "7e540290-ab4c-4502-f4f5-a2b88ae05cd1"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    collate_fn=encoder.collate_fn,\n",
    "    max_epochs=3,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    accelerator=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma8w-aMTZudm"
   },
   "source": [
    "## Encode the tokens using pre-trained transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_38pcl-Oly4l"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299,
     "referenced_widgets": [
      "29b4ffe53a2d4701ab9e8b20f6aeba67",
      "75a36c85a2bb4abbafbb35157a61c7d0",
      "73617dce96f643d9b897be80152edba6",
      "6dc1ae75c610481bb4e547d167caee50",
      "e689971fccaa497ba9bb5a2750ab66b0",
      "96f5f1ec5cf6484ab41407dc3ec6b558",
      "2f3ffb77f50a4ddb926354747ad00722",
      "8c94f49f919b4495bb0185e4b596d90a",
      "55731d4f920141bbb4eeb1a188542949",
      "e6a7c0dc82f44a4b8e3e6444201b08bc",
      "0d2d45713e38445eb98a3db8bcebcba8",
      "7edb4ce4819a4b42a72a8854ed3f0f66",
      "5512cfdc464a40d8adc8f0d7c60d35dc",
      "249f4ecd4c3249b5970ab7bbebce887e",
      "8955416e29184a2dbbb972ea5d383071",
      "36a57736932a48eaa59b7ada44a74d38",
      "88bf75f8e5d7473bb193b5fec3cf9edc",
      "5f60cdb6a14b47e98b8972c7d748a25b",
      "8284d57e0e364c2da79929c35c84607f",
      "dbee184030bf40ffb1b46fb5c7017b7b",
      "9af3c53b8c504dbeb100529558bf384b",
      "f16263ec82e44a08ab4d0db775558779",
      "41e7984697fa447fb2ceaca2c7df4d0e",
      "26f8e735ea0a4eac969286035fd5f3c6",
      "79afaee97f734f67876d65c0342f0a39",
      "8341df98921b49ae8c6652699cc4ed1c",
      "310e2b7af50549c1ad07338579f85f68",
      "5c30391840114cbf80a55095eb829486",
      "64ce0e5beb734694a89ac0ebcc9265f9",
      "2f2c1951bb6b422b83a33056896ad33b",
      "1bd7019e642c4b30b65ed9a71a9b0578",
      "97562051be58464793ca27647d312569",
      "db3c913b4a854e68873aaadad1065d83",
      "6d3a41d6944b422fb42f42e7e6e5fc6e",
      "b228d72cb6b74affbc233503987511ba",
      "2780d0f49aed41fd84810f82814ce924",
      "c7b90f532b2a4a4582af0128de31c22b",
      "8b67a2b8b42b4aada1face78c62e47e4",
      "74ce1c440fb6472da5d9d802b0a2e05d",
      "0eae7b1c001b4111b63663ee7466fd6c",
      "fd7892cc9fff44ed95f5243b464f95c2",
      "0e079135d6494992aca33f96c11c3392",
      "0c5bdd112a6e42f88b4d3dbc27ec3c2e",
      "629af921e3ae4d57a0c3ba747e7644cb",
      "70f5fb29ebd84f439a7cc563a15e7171",
      "402d28a31d79484dacc7f9fd0de42379",
      "aac2b6a872064c2a8b7aec4f38b29586",
      "c1a277b2ad6040ed914c80460f1fad91",
      "3a44e458d0d24deba3f21e3a8f4fa8d6",
      "e820306e2d3345739c4427e67f1bb251",
      "9c6b48413b654505be3e00523d58c6be",
      "65fa1ba514c942269b898d12ea7df05c",
      "daa92ba60ff343a6be8632e0fc08f512",
      "1d65cb00c38c41788c408563aa431d84",
      "ec5b151439a144d4b42dc082797047e4"
     ]
    },
    "id": "-v2gqWU9ly4l",
    "outputId": "16cc0874-80d1-4b69-8c7d-8ca4accb24c3"
   },
   "outputs": [],
   "source": [
    "# Let's see an example on how to use a pre-trained model to encode texts\n",
    "# in this case, we load the tokenizer and the transformer from the Hugging Face model hub\n",
    "# each model has its own tokenizer, compatible with the model's architecture/input format\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "sentence = \"This movie is great, the best I've seen!\"\n",
    "tokenizer_out = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(f\"Tokenizer output: {tokenizer_out}\\n\")\n",
    "\n",
    "print(\n",
    "    f\"The sentence is tokenized as: {tokenizer.convert_ids_to_tokens(tokenizer_out['input_ids'][0])}\"\n",
    ")\n",
    "print(f\"With a total of {len(tokenizer_out['input_ids'][0])} tokens\\n\")\n",
    "# Notice how the the first token is the special token [CLS] and the last one is [SEP]\n",
    "\n",
    "\n",
    "model_out = model(\n",
    "    **tokenizer_out\n",
    ")  # we can pass the tokenizer output directly to the model\n",
    "sentence_encoding = model_out.last_hidden_state\n",
    "print(\n",
    "    f\"Sentence encoding: {sentence_encoding.shape}\"\n",
    ")  # (batch_size, sequence_length, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11JEPb98ditd"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hf_model_name: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tokenizer = ...  # fill this with the right tokenizer\n",
    "        self.transformer = ...  # fill this with the right transformer\n",
    "\n",
    "        # we don't want to train the transformer, so we freeze its parameters and put it in eval mode\n",
    "        self.transformer.requires_grad_(False).eval()\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"You can ignore this method, it is automatically used to prepare the batch for the forward method.\"\"\"\n",
    "\n",
    "        texts = [sample[\"text\"] for sample in batch]\n",
    "        tokenizer_out = self.tokenizer(\n",
    "            texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=150\n",
    "        )\n",
    "        labels = [sample[\"label\"] for sample in batch]\n",
    "        return {\n",
    "            \"texts\": texts,\n",
    "            \"tokenizer_out\": tokenizer_out,\n",
    "            \"labels\": torch.as_tensor(labels),\n",
    "        }\n",
    "\n",
    "    def forward(self, batch: Mapping[str, Any]) -> torch.Tensor:\n",
    "        \"\"\"We want this function to return the encoding of each sentence in the batch.\n",
    "        The encoding will be selected from the last hidden state of the model output.\n",
    "        From the last hidden state, we will select the encoding corresponding to the [CLS] token for each sentence.\n",
    "        Then, we will return the encodings as a tensor of shape (batch_size, hidden_size), ready to be used by the classifier.\"\"\"\n",
    "\n",
    "        # the batch here already contains the output of the tokenizer\n",
    "        # it is associated with the \"tokenizer_out\" key in the batch dictionary\n",
    "        model_out = (\n",
    "            ...\n",
    "        )  # call the transformer with the tokenizer output, selecting the last hidden state for each sentence\n",
    "        # the shape of model_out should be (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        sentence_encoding = (\n",
    "            ...\n",
    "        )  # then select the encoding corresponding to the [CLS] token for each sentence\n",
    "        # the shape of the sentence_encoding should be (batch_size, hidden_size)\n",
    "\n",
    "        return sentence_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dac5f1c02569487ca4e0e3acd94af51f",
      "06bfa3baea1748ec81b4dfa73be017a8",
      "0f7341d42f724df188e4830fb0e13a52",
      "ab2ca0732c684058b51933058b30a86e",
      "3fd50f97aa524b2abcc8ae2bf2e6ac43",
      "01f24dc516034b2dac81c1119a16338d",
      "189537516fe74772951c2d942145dd5d",
      "74dbb968845648dca3e8cbe7fbc12826",
      "62f40f9164e74a5e861dfe610971bff1",
      "14a43812985943af87106817552c03ce",
      "bde7cb60881241628da6af0020290d2a",
      "5ae4d3de65244079b5020cde04707533",
      "dbd1a3f0af534ce8b6c6d961cadedd0b",
      "843d98b21b68400483e5271886d7ace3",
      "f026c9c169174dc09f7265522cbc0436",
      "cc0c05eba72a4592a0c64f2886eabcb9",
      "89bcd270c89f44658eb6ad746e9821a0",
      "4d7f3eecf3674b9cbf6303ee7991b811",
      "07588f8ad5e74df59810b1ee3c1ead45",
      "984fd3c46cd94d9bb3c6baaa8277ea9a",
      "72a28ee85f7641329c925269f4d57d99",
      "dc6e9384bbe0429eb19a5ac80698d3ac",
      "d56059f44a4b4c43a3f97e96550a8f3b",
      "105e06f18da54252bb1699d490723c67",
      "a500783c2d1848caac446ca7424662a5",
      "c1ae8f3c8ec04e47b767d54c541c07c4",
      "fd85892eabc34d53b71540d8a276cf3f",
      "584eeff2b88a458d926be0a4e7cb855d",
      "20a96b73331c404085c1fac13dfc43e0",
      "27de3b7493fe431fbe6c10be1bae8cae",
      "a7a6b7fe98714066a5f35e7ba5983d43",
      "407e619e47a844a18e66f75883f42d81",
      "463fc19cf22c4b10b6ee2354652d2e9d",
      "cf7e434ba499460da454d1e5920b5aeb",
      "a25278d05bb941dc88a4087715e6c0a6",
      "ca0558428690488e85d1a218501d8530",
      "320ebdad93a44426a966e8b12805496a",
      "561159b1708f4155afa8c2482a9d50f2",
      "b55d9ad8e9cc44a8ac9f78f3e9239023",
      "fe5607b3cbfe4cc0a31d1c854d61d1eb",
      "02c21d8f23584798b94c2f2646b86cb0",
      "fe45f5dfa0da40f698151398c448f9d4",
      "440af66057ff4d22bbacb89704a98525",
      "49f8e3c33d854d2788411b9830a86acb",
      "dd42fd451273493c9c835b6488f6c6d2",
      "080b9efb4e794985b2251c0be2aa7c2f",
      "8890553585a04052a7961508391b46ab",
      "8c2eaea76ea34f888a545c60f29b747c",
      "2e2ae06dbe924dfaa67f8a14fb239dab",
      "b1572dfe541b4935b6564d32660e0ed5",
      "b872c6c8d776497a80283e6fcadb80d5",
      "ebd32c6d90e64783a9e073907e0ccf92",
      "b10cba741ceb44b5bb2997909e2cb460",
      "26fdccb83e8e433fa7e620331b453d2f",
      "5b144ea66384495b811d27688627c385",
      "02b5ff9d6a9e4a94a02f4df81e96b6a8",
      "005b18db41a143ccac82194896903803",
      "3834cec676354e93813b56ff886f8046",
      "4a24a3c949294e22b97b13d69a7bf748",
      "281342a4ba634dd7a3392adafad21433",
      "65f6552a17dd4679b010f78c7aa912d4",
      "c91a5ac805654f6f8d000ce474bcbe87",
      "4f684218044e45ebb12de7ffdb9ba0de",
      "e4d67b83723042dc810394b222fa53c4",
      "de3af9b4c94f450784c82231a2b8fe63",
      "7fd121569d0940c6bb0ab609bf276806"
     ]
    },
    "id": "o1cqCupxly4l",
    "outputId": "ff83c026-322b-4170-872c-cfc1ade849a2"
   },
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\"\n",
    "encoder = TransformerEncoder(hf_model_name=model_name)\n",
    "encoding_dim = encoder.transformer.config.hidden_size\n",
    "\n",
    "model = SimpleClassifier(\n",
    "    TransformerEncoder(hf_model_name=model_name),\n",
    "    encoding_dim=encoding_dim,\n",
    "    n_classes=train_data.features[\"label\"].num_classes,\n",
    "    train_encoder=False,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871,
     "referenced_widgets": [
      "a468a1225d4043ddb5fb606ca88abc59",
      "71d0e93caa53471591b566e21aadcb9f",
      "00fb0f23652a4448bfdd541b66555bb5",
      "41cae5e685ce4a55a1205e026d94bc35",
      "347c51552529493782817b57f460c8ed",
      "f5ff96bbb6eb4bd0a1f9b6075c10ecbc",
      "833f39469ef64ad59212c951eacf2763",
      "0b851bcf74d8455c8ecb5127e5a0bbfe",
      "bafcf2ce4b95418eb4607176468439b1",
      "6549994e08f04fa1815acf0f29d57916",
      "04be25cc87594c7e86017773867b6420",
      "e6856952b927436f953d9a13737434c1",
      "1fa825375c6640bd90759007b650fa68",
      "b615fa55700a47b4a7af0c470c64b54a",
      "d4373f3c8f27485780eb59f073e2290b",
      "f7c625bac2c045ab896d7b43094d7014",
      "3abe01a7e9dd43e39906bee7f4a80b65",
      "80c40141e0e3432d81cf75a5d84ca811",
      "9decb443127d4f459aee58324dbffd76",
      "d606b89d30244917ad4239f2c4293285",
      "c9e44e8480cf4ab2ba37b1daa55d8d44",
      "d744713ecb2f4896b31c7852ddd58b5b",
      "337e69f4e1b04c23944486283b2aa7f1",
      "a9a4c81dbd1b408a8c9a67f517f6d821",
      "482376c96c77470ab455657aaf4d89d0",
      "08a01ac1ea444086adbaef2fdee38695",
      "f7004ac62dbd4e79afd3da97aa9bd6d6",
      "09aebbbd5d1145f092120c49050dce2d",
      "3828e2fc35714106a0de1a1696657f9c",
      "5f45c710194a4132b28e77257eace6e5",
      "3bd8c8f8c111439d8d294fbbf6444efe",
      "e45086302b75440aa870010fe2e9d4bc",
      "46612535f8ad4a008c9246075ea0d004",
      "ee0b4cecfa064513a2a765f3c55f74b0",
      "89bb501bc2124c49b556e4185e955111",
      "ac3c43fc2bca4753a6d4ece7f6cd0df6",
      "7f4875fc809143b8b529bdbba4472f07",
      "913866d6aca54dd4906d79d880ea2b44",
      "65178a1378df4eb5b34a66dfb17bf5aa",
      "112f38de50c34ed48e435816bd4d05c3",
      "ad382301985d40c68b752ceca1977a27",
      "09f0fe0e2d4a433d862df818ba085fe9",
      "30765c2668484cc9b00d16efa6e6115e",
      "c4f6c5a091d4480ca94c8fef10b22b5a",
      "d3352ec385f249e3965b0f8c8c1470f4",
      "0b0e02ba711744e5a2c0676e806d85dc",
      "742dd2c811664d308c22fe5988d0d304",
      "3b62da8f7e9d471fa824423e056e2187",
      "77c3d85e3ca04cdd996c223c9cbaf2e8",
      "750e5c4825c645839eab726bafc8f9b5",
      "d11cc4ebd290459f841ad20ec2c5d1bb",
      "d43df855622540f6a28217dd216aefcf",
      "ba669784705e4db3bfcc9de383490219",
      "e6cee33b9b974d01b127690c0894b39e",
      "5ea5c56264f04523a5c8fd9244bf5ae6",
      "2cd2c990802e48239b6d02075718e3ea",
      "78e7d4da0da3440caad5ee34650dd88f",
      "36ce31a4ae5b43118c9db4b1a0a9cff1",
      "843f0226739449ff953b1231c7388be5",
      "28dc7d3be45c4ad292b1de4818126aeb",
      "c2a2f2e414e144d8ad9f4664804fd073",
      "556ff85a30284db5b49a1ed0af513713",
      "ea45e3e1f4f5402e8f5c44b4eb50ca86",
      "d9e945c6dd9f47adb55d00fbfdbc11fe",
      "b58ee425bfa443118a39d9d09f3fb383",
      "fe068fa590794e4192b8073104f00957"
     ]
    },
    "id": "KdwEPaSply4l",
    "outputId": "341bcc9b-f50c-48fe-df97-1620e80d79c6"
   },
   "outputs": [],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    collate_fn=encoder.collate_fn,\n",
    "    max_epochs=3,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    accelerator=\"auto\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
